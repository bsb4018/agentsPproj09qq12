{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b279fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "import os\n",
    "from langsmith import traceable\n",
    "import json\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68e19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY=os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "AZURE_OPENAI_ENDPOINT=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_API_VERSION=os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692d8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o-mini\",\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "kernel.add_service(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bd2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class IntentAnalysis(BaseModel):\n",
    "    intent: str = Field(description=\"What the user wants to achieve\")\n",
    "    domain: str = Field(description=\"Domain of the question\")\n",
    "    complexity: str = Field(description=\"easy, medium, hard\")\n",
    "\n",
    "class PlanOutput(BaseModel):\n",
    "    steps: List[str] = Field(description=\"Steps to answer the question\")\n",
    "    tools_needed: List[str] = Field(description=\"Tools or knowledge required\")\n",
    "\n",
    "class ResponderOutput(BaseModel):\n",
    "    final_answer: str = Field(description=\"Final answer of the user question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd04607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_prompt = \"\"\"\n",
    "You are an AI that analyzes user queries.\n",
    "\n",
    "Extract:\n",
    "- intent\n",
    "- domain\n",
    "- complexity\n",
    "\n",
    "User Query: {{$input}}\n",
    "\n",
    "Return JSON.\n",
    "\"\"\"\n",
    "\n",
    "request_settings_intent = AzureChatPromptExecutionSettings(response_format=IntentAnalysis)\n",
    "intent_function = kernel.add_function(\n",
    "    plugin_name=\"analysis\",\n",
    "    function_name=\"intent_analyzer\",\n",
    "    prompt=intent_prompt,\n",
    "    prompt_execution_settings=request_settings_intent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527ca758",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_prompt = \"\"\"\n",
    "You are a planner agent.\n",
    "\n",
    "Based on this analysis:\n",
    "Intent: {{$intent}}\n",
    "Domain: {{$domain}}\n",
    "Complexity: {{$complexity}}\n",
    "\n",
    "Create:\n",
    "- steps to solve\n",
    "- tools needed\n",
    "\n",
    "Return JSON.\n",
    "\"\"\"\n",
    "\n",
    "request_settings_planner = AzureChatPromptExecutionSettings(response_format=PlanOutput)\n",
    "planner_function = kernel.add_function(\n",
    "    plugin_name=\"planner\",\n",
    "    function_name=\"plan_creator\",\n",
    "    prompt=planner_prompt,\n",
    "    prompt_execution_settings=request_settings_planner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e37b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "responder_prompt = \"\"\"\n",
    "You are an expert AI assistant.\n",
    "\n",
    "Follow this plan:\n",
    "{{$steps}}\n",
    "\n",
    "User question:\n",
    "{{$question}}\n",
    "\n",
    "Provide a detailed answer.\n",
    "\"\"\"\n",
    "\n",
    "request_settings_responder = AzureChatPromptExecutionSettings(response_format=ResponderOutput)\n",
    "responder_function = kernel.add_function(\n",
    "    plugin_name=\"responder\",\n",
    "    function_name=\"answer_generator\",\n",
    "    prompt=responder_prompt,\n",
    "    prompt_execution_settings=request_settings_responder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Explain how hybrid retrieval improves RAG systems\"\n",
    "intent_result = await kernel.invoke(intent_function, input=user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb403d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionResult(function=KernelFunctionMetadata(name='intent_analyzer', plugin_name='analysis', description=None, parameters=[KernelParameterMetadata(name='input', description='', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object'}, include_in_function_choices=True)], is_prompt=True, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None, include_in_function_choices=True), additional_properties=None), value=[ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-D4iXQQaomY3wZRqrrhIBJ02RclcBF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"intent\":\"Understand how hybrid retrieval enhances retrieval-augmented generation systems\",\"domain\":\"Information Retrieval / Natural Language Processing\",\"complexity\":\"medium\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1770016888, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_f97eff32c5', usage=CompletionUsage(completion_tokens=30, prompt_tokens=129, total_tokens=159, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]), ai_model_id='gpt-4o-mini', metadata={'logprobs': None, 'id': 'chatcmpl-D4iXQQaomY3wZRqrrhIBJ02RclcBF', 'created': 1770016888, 'system_fingerprint': 'fp_f97eff32c5', 'usage': CompletionUsage(prompt_tokens=129, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), completion_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0))}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='{\"intent\":\"Understand how hybrid retrieval enhances retrieval-augmented generation systems\",\"domain\":\"Information Retrieval / Natural Language Processing\",\"complexity\":\"medium\"}', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>, status=None)], rendered_prompt='\\nYou are an AI that analyzes user queries.\\n\\nExtract:\\n- intent\\n- domain\\n- complexity\\n\\nUser Query: Explain how hybrid retrieval improves RAG systems\\n\\nReturn JSON.\\n', metadata={'arguments': {'input': 'Explain how hybrid retrieval improves RAG systems'}, 'metadata': [{'logprobs': None, 'id': 'chatcmpl-D4iXQQaomY3wZRqrrhIBJ02RclcBF', 'created': 1770016888, 'system_fingerprint': 'fp_f97eff32c5', 'usage': CompletionUsage(prompt_tokens=129, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), completion_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0))}], 'messages': ChatHistory(messages=[ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='You are an AI that analyzes user queries.\\n\\nExtract:\\n- intent\\n- domain\\n- complexity\\n\\nUser Query: Explain how hybrid retrieval improves RAG systems\\n\\nReturn JSON.', encoding=None)], encoding=None, finish_reason=None, status=None)]), 'prompt': '\\nYou are an AI that analyzes user queries.\\n\\nExtract:\\n- intent\\n- domain\\n- complexity\\n\\nUser Query: Explain how hybrid retrieval improves RAG systems\\n\\nReturn JSON.\\n'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512329de",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_answer = IntentAnalysis.model_validate(json.loads(intent_result.value[0].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46fc48bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Understand how hybrid retrieval enhances retrieval-augmented generation systems'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_answer.intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e8da49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Information Retrieval / Natural Language Processing'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_answer.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b1d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_answer.complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ba7893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Intent Analyzer Step\")\n",
    "async def run_intent_step(user_question):\n",
    "    intent_result = await kernel.invoke(intent_function, input=user_question)\n",
    "    return IntentAnalysis(**json.loads(str(intent_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe574b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Planner Step\")\n",
    "async def run_planner_step(intent_data):\n",
    "    plan_result = await kernel.invoke(\n",
    "        planner_function,\n",
    "        intent=intent_data.intent,\n",
    "        domain=intent_data.domain,\n",
    "        complexity=intent_data.complexity,\n",
    "    )\n",
    "    return PlanOutput(**json.loads(str(plan_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Responder Step\")\n",
    "async def run_responder_step(plan_data, user_question):\n",
    "    responder_response = await kernel.invoke(\n",
    "        responder_function,\n",
    "        steps=\"\\n\".join(plan_data.steps),\n",
    "        question=user_question,\n",
    "    )\n",
    "    return ResponderOutput(**json.loads(str(responder_response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Prompt Chaining Agent\")\n",
    "async def prompt_chaining_agent(user_question: str):\n",
    "\n",
    "    # --- Step 1: Intent Analysis ---\n",
    "    intent_data = await run_intent_step(user_question)\n",
    "\n",
    "    # --- Step 2: Planning ---\n",
    "    plan_data = await run_planner_step(intent_data)\n",
    "\n",
    "    # --- Step 3: Response ---\n",
    "    final_answer = await run_responder_step(plan_data, user_question)\n",
    "\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab01b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await prompt_chaining_agent(\n",
    "    \"Explain how hybrid retrieval improves RAG systems\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a445d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Retrieval-Augmented Generation (RAG) systems represent a significant advancement in the fields of information retrieval (IR) and natural language processing (NLP). By integrating retrieval mechanisms with generative models, RAG systems can enhance the quality and relevance of the content they produce.\\n\\n### Definition of RAG Systems\\nRAG systems operate by combining two distinct components: a retriever and a generator. The retriever searches an external knowledge base or database for relevant documents or snippets related to a user's query. The retrieved information is then fed into a generative model, which constructs coherent and contextually appropriate responses based on the retrieved content.\\n\\n### Relevance of RAG in Information Retrieval and NLP\\nRAG systems are particularly relevant in addressing the limitations of traditional models that rely solely on pre-existing knowledge in their training data. They enable dynamic information access, improving the robustness and accuracy of responses in various applications, including conversational agents, content creation, and question-answering systems.\\n\\n### Components of Hybrid Retrieval Systems\\nHybrid retrieval systems incorporate multiple retrieval techniques, typically combining:\\n1. **Traditional Keyword-Based Search**: Utilizing pre-defined indexes and ranking algorithms that match user queries with text data based on keyword occurrences.\\n2. **Semantic Search**: Leveraging advanced NLP techniques and embeddings (such as BERT or other language models) to understand the context and meaning of queries, aiming to deliver results that align more closely with user intent.\\n3. **Vector-Based Retrieval**: Using vector representations of documents and queries to enable similarity search, improving retrieval accuracy by finding semantically similar content even if specific keywords are not present.\\n\\n### Comparison to Traditional Retrieval Methods\\nTraditional retrieval systems often rely heavily on keyword matching, which may fail to capture the nuances of user intent, leading to suboptimal retrieval performance. In contrast, hybrid retrieval systems:\\n- Combine keyword-based and semantic techniques, enhancing the breadth and depth of retrieval.\\n- Address ambiguity in language and provide more relevant and context-aware results.\\n\\n### Benefits of Hybrid Retrieval Systems in RAG\\n1. **Improved Accuracy**: By integrating various retrieval approaches, hybrid systems can yield more precise results, reducing the likelihood of irrelevant or low-quality content being presented to users.\\n2. **Diversity of Search Results**: Hybrid retrieval techniques help in presenting diverse content perspectives, which is particularly useful in generating responses that cater to different user intents and scenarios.\\n3. **Enhanced Context Retrieval**: The use of semantic search and vector-based techniques allows RAG systems to retrieve contextually relevant information, thus enriching the quality and relevance of the generated responses.\\n\\n### Case Studies and Research Demonstrating Effectiveness\\nThere have been several studies and implementations showcasing the effectiveness of hybrid retrieval in RAG systems:\\n- **Googleâ€™s T5 Model**: Various research papers highlight T5's ability to integrate fine-tuned retrieval methods with its generative model, improving accuracy over traditional approaches.\\n- **FAIR's RAG Model**: The original paper detailing the RAG architecture illustrated significant improvements in performance on benchmarks by incorporating flexible retrieval strategies.\\n- **Chatbot Implementations**: Many commercial chatbots utilize hybrid retrieval systems to enhance their responses, showing better user engagement and satisfaction by pulling in data from multiple sources simultaneously.\\n\\n### Summary of Key Points and Advantages\\nIn summary, hybrid retrieval systems significantly improve RAG applications by enabling a more accurate, diverse, and context-aware response generation process. By combining the strengths of various retrieval methodologies, these systems help provide richer and more informative interactions, catering effectively to user needs and producing high-quality content.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de7f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6430442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb1d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c06b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10162a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
