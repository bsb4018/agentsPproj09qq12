{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langsmith import traceable\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f05aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a85e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    explanation: str\n",
    "    examples: str\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "# class AgentState(BaseModel):\n",
    "#     user_query: str = Field(..., description=\"Original User Question\")\n",
    "#     explanation: Optional[str] = Field(None, description=\"Detailed Answer to the User Question\")\n",
    "#     examples: Optional[str] = Field(None, description=\"Relevant Examples Illustrating the Answer\")\n",
    "#     final_answer: Optional[str] = Field(None, description=\"Concise Final Answer for the User\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3294458",
   "metadata": {},
   "source": [
    "### Node 1 : Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f023fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Explain Node\")\n",
    "def explain_concept(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Explain the following topic in simple beginner-friendly terms:\n",
    "\n",
    "    Topic: {state.user_query}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"explanation\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581514a8",
   "metadata": {},
   "source": [
    "### Node 2 - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba70851",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Example Node\")\n",
    "def generate_examples(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Based on this explanation:\n",
    "\n",
    "    {state.explanation}\n",
    "\n",
    "    Provide 3 real-world examples.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"examples\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1c27a",
   "metadata": {},
   "source": [
    "### Node 3 â€” Summary Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Summarize Node\")\n",
    "def summarize_all(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Explanation:\n",
    "    {state.explanation}\n",
    "\n",
    "    Examples:\n",
    "    {state.examples}\n",
    "\n",
    "    Create a short summary for revision.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"final_answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6295e5",
   "metadata": {},
   "source": [
    "### Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"explain\", explain_concept)\n",
    "workflow.add_node(\"examples\", generate_examples)\n",
    "workflow.add_node(\"summary\", summarize_all)\n",
    "\n",
    "workflow.set_entry_point(\"explain\")\n",
    "workflow.add_edge(\"explain\", \"examples\")\n",
    "workflow.add_edge(\"examples\", \"summary\")\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c15149",
   "metadata": {},
   "source": [
    "### Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4063a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(\n",
    "    AgentState(user_query=\"What is overfitting in machine learning?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be69d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25703aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2aed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44a22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb07caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4129cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2f452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b7d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1496f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentsPproj09qq12 (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
