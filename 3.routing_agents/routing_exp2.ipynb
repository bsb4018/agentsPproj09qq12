{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f9e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "import os\n",
    "from langsmith import traceable\n",
    "import json\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3017cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY=os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "AZURE_OPENAI_ENDPOINT=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_API_VERSION=os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2035d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "service = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o-mini\",\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "kernel.add_service(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6322744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    agent: str = Field(description=\"Which agent to route to: tech, math, general\")\n",
    "    reason: str = Field(description=\"Why this agent is appropriate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = \"\"\"\n",
    "You are a routing agent.\n",
    "\n",
    "Decide which expert should answer.\n",
    "\n",
    "Options:\n",
    "- tech → programming, AI, systems\n",
    "- math → calculations, formulas\n",
    "- general → anything else\n",
    "\n",
    "User Question: {{$input}}\n",
    "\n",
    "Return JSON with:\n",
    "- agent\n",
    "- reason\n",
    "\"\"\"\n",
    "request_settings_router = AzureChatPromptExecutionSettings(temperature=0,\n",
    "                                                           max_tokens=100,\n",
    "                                                           response_format=RouteDecision)\n",
    "router_function = kernel.add_function(\n",
    "    plugin_name=\"router\",\n",
    "    function_name=\"route_query\",\n",
    "    prompt=router_prompt,\n",
    "    prompt_execution_settings=request_settings_router\n",
    ")\n",
    "\n",
    "@traceable(name=\"Router Step\")\n",
    "async def run_router_step(user_question: str) -> RouteDecision:\n",
    "    result = await kernel.invoke(router_function, input=user_question)\n",
    "    return RouteDecision(**json.loads(str(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_prompt = \"\"\"\n",
    "You are a senior software and AI engineer.\n",
    "Answer clearly and technically.\n",
    "\n",
    "Question: {{$input}}\n",
    "\"\"\"\n",
    "request_settings_tech = AzureChatPromptExecutionSettings(temperature=0,max_tokens=200)\n",
    "tech_function = kernel.add_function(plugin_name=\"experts\", function_name=\"tech_agent\", prompt=tech_prompt, prompt_execution_settings=request_settings_tech)\n",
    "\n",
    "@traceable(name=\"Tech Expert Step\")\n",
    "async def run_tech_expert(user_question: str):\n",
    "    return await kernel.invoke(tech_function, input=user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acbb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_prompt = \"\"\"\n",
    "You are a mathematician.\n",
    "Show formulas and steps.\n",
    "\n",
    "Question: {{$input}}\n",
    "\"\"\"\n",
    "request_settings_math = AzureChatPromptExecutionSettings(temperature=0,max_tokens=400)\n",
    "math_function = kernel.add_function(plugin_name=\"experts\", function_name=\"math_agent\",\n",
    "                                    prompt=math_prompt,prompt_execution_settings=request_settings_math)\n",
    "\n",
    "@traceable(name=\"Math Expert Step\")\n",
    "async def run_math_expert(user_question: str):\n",
    "    return await kernel.invoke(math_function, input=user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Question: {{$input}}\n",
    "\"\"\"\n",
    "request_settings_general = AzureChatPromptExecutionSettings(temperature=0,max_tokens=200)\n",
    "general_function = kernel.add_function(plugin_name=\"experts\", function_name=\"general_agent\", \n",
    "                                       prompt=general_prompt,prompt_execution_settings=request_settings_general)\n",
    "\n",
    "@traceable(name=\"General Expert Step\")\n",
    "async def run_general_expert(user_question: str):\n",
    "    return await kernel.invoke(general_function, input=user_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd0f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Routing Agent\")\n",
    "async def routing_agent(user_question: str):\n",
    "\n",
    "    # Step 1: Router\n",
    "    decision = await run_router_step(user_question)\n",
    "    print(f\"[Router] → {decision.agent} | {decision.reason}\")\n",
    "\n",
    "    # Step 2: Delegate\n",
    "    if decision.agent == \"tech\":\n",
    "        answer = await run_tech_expert(user_question)\n",
    "\n",
    "    elif decision.agent == \"math\":\n",
    "        answer = await run_math_expert(user_question)\n",
    "\n",
    "    else:\n",
    "        answer = await run_general_expert(user_question)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3d9c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] → tech | The question pertains to hybrid retrieval in RAG (Retrieval-Augmented Generation) systems, which involves technical concepts related to programming and AI.\n"
     ]
    }
   ],
   "source": [
    "result = await routing_agent(\n",
    "    \"How does hybrid retrieval improve RAG systems?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79a53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retrieval enhances Retrieval-Augmented Generation (RAG) systems by combining different retrieval methods to improve the quality and relevance of the information retrieved for generating responses. Here’s a breakdown of how hybrid retrieval contributes to RAG systems:\n",
      "\n",
      "### 1. **Combining Strengths of Different Retrieval Approaches:**\n",
      "   - **Dense Retrieval:** Utilizes neural embeddings to capture semantic similarity. It excels in retrieving relevant documents based on meaning rather than keyword matching. This is particularly useful for understanding context and nuances in queries.\n",
      "   - **Sparse Retrieval:** Relies on traditional keyword-based methods (like TF-IDF or BM25). It is effective for retrieving documents that contain specific terms or phrases, ensuring that exact matches are not overlooked.\n",
      "   - **Hybrid Approach:** By integrating both dense and sparse retrieval, RAG systems can leverage the strengths of each method. For example, sparse retrieval can quickly filter a large corpus to a smaller set of potentially relevant documents, while dense retrieval can then refine this set based on semantic relevance.\n",
      "\n",
      "### 2. **Improved Recall and Precision:**\n",
      "   - **Recall:** The hybrid approach increases the likelihood of retrieving relevant documents that might be missed by either method alone. Sparse retrieval can catch documents with exact keyword matches, while dense retrieval can find semantically similar documents that may not share the same keywords.\n",
      "   - **Precision:** By filtering the results from sparse retrieval with dense retrieval, the system can improve the precision of the final output, ensuring that the most relevant documents are used for generating responses.\n",
      "\n",
      "### 3. **Contextual Understanding:**\n",
      "   - Hybrid retrieval can better handle ambiguous queries by using dense retrieval to understand the context and intent behind the query. This allows the system to retrieve documents that are contextually relevant, even if they do not contain the exact keywords from the query.\n",
      "\n",
      "### 4. **Scalability and Efficiency:**\n",
      "   - Sparse retrieval methods are generally faster and can handle larger datasets efficiently. By using sparse retrieval as a first step,\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc53d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700aabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d51c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff3aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b12f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9aaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
