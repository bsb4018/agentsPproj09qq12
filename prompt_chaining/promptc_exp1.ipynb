{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langsmith import traceable\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f05aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc7569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a85e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba48b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    user_query: str = Field(..., description=\"Original User Question\")\n",
    "    explanation: Optional[str] = Field(None, description=\"Detailed Answer to the User Question\")\n",
    "    examples: Optional[str] = Field(None, description=\"Relevant Examples Illustrating the Answer\")\n",
    "    final_answer: Optional[str] = Field(None, description=\"Concise Final Answer for the User\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3294458",
   "metadata": {},
   "source": [
    "### Node 1 : Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f023fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Explain Node\")\n",
    "def explain_concept(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Explain the following topic in simple beginner-friendly terms:\n",
    "\n",
    "    Topic: {state.user_query}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"explanation\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581514a8",
   "metadata": {},
   "source": [
    "### Node 2 - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba70851",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Example Node\")\n",
    "def generate_examples(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Based on this explanation:\n",
    "\n",
    "    {state.explanation}\n",
    "\n",
    "    Provide 3 real-world examples.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"examples\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1c27a",
   "metadata": {},
   "source": [
    "### Node 3 â€” Summary Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ba7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Summarize Node\")\n",
    "def summarize_all(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    Explanation:\n",
    "    {state.explanation}\n",
    "\n",
    "    Examples:\n",
    "    {state.examples}\n",
    "\n",
    "    Create a short summary for revision.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"final_answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6295e5",
   "metadata": {},
   "source": [
    "### Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6208eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"explain\", explain_concept)\n",
    "workflow.add_node(\"examples\", generate_examples)\n",
    "workflow.add_node(\"summary\", summarize_all)\n",
    "\n",
    "workflow.set_entry_point(\"explain\")\n",
    "workflow.add_edge(\"explain\", \"examples\")\n",
    "workflow.add_edge(\"examples\", \"summary\")\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c15149",
   "metadata": {},
   "source": [
    "### Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4063a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(\n",
    "    AgentState(user_query=\"What is overfitting in machine learning?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be69d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Overfitting: Revision Summary\n",
      "\n",
      "**What is Overfitting?**\n",
      "When a machine learning model learns the **training data *too perfectly***, memorizing specific details and noise rather than general patterns.\n",
      "\n",
      "**Analogy:**\n",
      "Like an **\"overfitting student\"** who memorizes *exact answers* to practice questions but fails on a real test with slightly different questions because they didn't understand the underlying concepts.\n",
      "\n",
      "**Key Characteristics:**\n",
      "*   **Excellent performance** on the data it was trained on (training data).\n",
      "*   **Poor performance** on new, unseen data (real-world data).\n",
      "*   It's **too specialized** in its training data.\n",
      "\n",
      "**In a Nutshell:**\n",
      "Your model has **memorized instead of learned**, making it ineffective and useless for real-world predictions on new situations.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25703aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're teaching a computer to do something, like recognize cats in pictures or predict house prices.\n",
      "\n",
      "Here's the simple breakdown of **overfitting**:\n",
      "\n",
      "---\n",
      "\n",
      "### The Goal of Machine Learning\n",
      "\n",
      "The whole point of machine learning is to teach a computer model to learn patterns from existing data (called **training data**) so it can make good predictions or decisions on **new, unseen data**.\n",
      "\n",
      "Think of it like a student studying for a test.\n",
      "\n",
      "### The Analogy: The Over-Studious Student\n",
      "\n",
      "1.  **The Good Student (Ideal Model):**\n",
      "    *   This student studies the *concepts* and *general rules* from their textbook and practice questions.\n",
      "    *   They understand *why* things work the way they do.\n",
      "    *   When they get to the real test, even if the questions are phrased slightly differently or are completely new, they can apply their understanding and do well.\n",
      "\n",
      "2.  **The Overfitting Student (Overfit Model):**\n",
      "    *   This student doesn't bother to understand the concepts. Instead, they **memorize *only* the answers to the specific practice questions** they were given.\n",
      "    *   They know those practice questions perfectly! If you give them the exact same practice test, they'll get 100%.\n",
      "    *   But what happens on the *real test*? If the questions are even slightly different, or if there are new questions they haven't memorized, they'll likely **fail badly**. They can't apply their \"knowledge\" to new situations.\n",
      "\n",
      "### Overfitting in Machine Learning Explained\n",
      "\n",
      "Now, let's bring this back to our computer model:\n",
      "\n",
      "*   **Training Data** = The practice questions the student memorized.\n",
      "*   **New, Unseen Data** = The real test questions.\n",
      "\n",
      "**Overfitting happens when your machine learning model acts like the \"overfitting student.\"**\n",
      "\n",
      "1.  **It learns the training data *too perfectly*.** It doesn't just learn the general patterns and rules; it also memorizes all the tiny details, specific quirks, and even the \"noise\" (random errors or irrelevant information) that are unique to *that particular* training set.\n",
      "\n",
      "2.  **It becomes *too specialized* in its training data.** It's like the model has drawn an incredibly complex, wiggly line that perfectly hits *every single data point* in the training set, rather than a smoother line that captures the overall trend.\n",
      "\n",
      "3.  **It fails on new data.** When you give this overfit model new data it hasn't seen before, it gets confused. Because the new data doesn't exactly match the specific details it memorized, the model makes poor predictions or decisions. It can't generalize its \"knowledge\" to real-world situations.\n",
      "\n",
      "### In a Nutshell:\n",
      "\n",
      "**Overfitting means your model performs *amazingly well* on the data it was trained on, but *very poorly* on any new data.** It has memorized instead of learned, making it useless for real-world predictions.\n",
      "\n",
      "It's a common challenge in machine learning, and there are many techniques to prevent it!\n"
     ]
    }
   ],
   "source": [
    "print(result[\"explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a2aed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 3 real-world examples of overfitting, based on the explanation:\n",
      "\n",
      "1.  **Medical AI for Disease Detection:**\n",
      "    *   **Scenario:** An AI model is developed to diagnose a rare skin disease by analyzing images of skin lesions. It's trained on a dataset of thousands of images, but all these images come from a single, highly specialized clinic. This clinic uses a specific type of camera, consistent lighting, and always positions the patient in the exact same way. The AI achieves an astonishing 99.9% accuracy on this training data.\n",
      "    *   **Overfitting:** The AI hasn't just learned the visual characteristics of the disease; it has also \"memorized\" the specific lighting conditions, camera artifacts, background elements, and even the subtle angle at which the photos were taken at that particular clinic. It's like the \"overfitting student\" who memorized the exact phrasing of practice questions.\n",
      "    *   **Failure on New Data:** When this AI is deployed to a different hospital that uses different cameras, has varying lighting, or takes photos from slightly different angles, its accuracy plummets. It fails to correctly diagnose the disease in new patients because the images don't perfectly match the specific visual \"signature\" it memorized from the training clinic. It can't generalize its \"knowledge\" to real-world variations.\n",
      "\n",
      "2.  **Customer Service Chatbot:**\n",
      "    *   **Scenario:** A company trains a chatbot to answer customer questions based on a very specific set of FAQs. The training data consists of thousands of examples where customers ask these exact questions, and the chatbot is taught the precise, pre-written answers. The chatbot performs perfectly when asked these exact questions.\n",
      "    *   **Overfitting:** The chatbot has \"memorized\" the exact phrasing of the questions and the specific wording of the answers. It's like it has a perfect lookup table for specific sentences, rather than understanding the *intent* behind the questions.\n",
      "    *   **Failure on New Data:** When a customer asks a question that means the same thing but uses slightly different wording, or asks a follow-up question that wasn't in the original FAQ list, the chatbot gets confused. It might respond with \"I don't understand\" or give an irrelevant answer because it can't generalize its knowledge beyond the exact phrases it memorized. It's like the \"overfitting student\" who fails when test questions are phrased differently.\n",
      "\n",
      "3.  **Fraud Detection System:**\n",
      "    *   **Scenario:** A bank develops a machine learning model to detect credit card fraud. It's trained on a historical dataset of fraudulent transactions, which, by chance, contains a disproportionately high number of fraudulent activities originating from a specific country and involving purchases of a particular type of luxury good (e.g., high-end electronics). The model becomes incredibly accurate at flagging these specific types of transactions.\n",
      "    *   **Overfitting:** The system has \"memorized\" the exact patterns of fraud present in its training data, including the specific country codes, merchant categories, and transaction amounts that were common in that historical dataset. It's become too specialized in those particular fraud schemes.\n",
      "    *   **Failure on New Data:** When fraudsters change their tactics and start committing fraud from different countries, or by purchasing different types of goods (e.g., travel services instead of electronics), the overfit system fails to detect these new forms of fraud. It's still looking for the *exact patterns* it memorized, rather than learning the underlying *indicators* of suspicious activity that might generalize across different fraud schemes. It's like the \"overfitting student\" who can't apply their memorized answers to new problems.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44a22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb07caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4129cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2f452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b7d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1496f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentsPproj09qq12 (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
